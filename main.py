import pandas as pd
import os
from datetime import datetime
import logging

# ğŸ¯ Configuration du logger
log_dir = "logs"
os.makedirs(log_dir, exist_ok=True)
log_filename = os.path.join(log_dir, f"log_pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
logging.basicConfig(
    filename=log_filename,
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

logging.info("DÃ©but du pipeline de traitement de donnÃ©es")

# 1ï¸âƒ£ Chargement des donnÃ©es
chemin = './jeu_donnees_etl_5000_lignes.csv'
df_original = pd.read_csv(chemin)
logging.info(f"Chargement du fichier : {chemin} â€” {df_original.shape[0]} lignes, {df_original.shape[1]} colonnes")

# 2ï¸âƒ£ Visualisation des premiÃ¨res lignes
print("ğŸ” AperÃ§u des donnÃ©es brutes :")
print(df_original.head())

# 3ï¸âƒ£ Informations gÃ©nÃ©rales
print("\nğŸ§± Infos structurelles :")
df_original.info()

# 4ï¸âƒ£ Statistiques gÃ©nÃ©rales
print("\nğŸ“Š Statistiques descriptives :")
print(df_original.describe(include='all'))

print(f"\nğŸ“ Dimensions initiales : {df_original.shape}")

# 5ï¸âƒ£ Nettoyage des doublons
df_clean = df_original.drop_duplicates()
nb_doublons = df_original.shape[0] - df_clean.shape[0]
logging.info(f"Suppression de {nb_doublons} doublons")
print(f"âœ… AprÃ¨s suppression des doublons : {df_clean.shape}")

# 6ï¸âƒ£ Traitement des valeurs extrÃªmes (winsorisation)
def limiter_extremes(colonne):
    q1 = colonne.quantile(0.25)
    q3 = colonne.quantile(0.75)
    iqr = q3 - q1
    borne_basse = q1 - 1.5 * iqr
    borne_haute = q3 + 1.5 * iqr
    return colonne.clip(lower=borne_basse, upper=borne_haute)

df_clean['Quantite_vendue'] = limiter_extremes(df_clean['Quantite_vendue'])
df_clean['Prix_unitaire'] = limiter_extremes(df_clean['Prix_unitaire'])
logging.info("Application de la winsorisation sur 'Quantite_vendue' et 'Prix_unitaire'")

# 7ï¸âƒ£ Suppression des lignes avec des champs critiques manquants
df_clean.dropna(subset=['Nom_produit', 'Prix_unitaire'], inplace=True)
logging.info("Suppression des lignes avec valeurs manquantes dans 'Nom_produit' ou 'Prix_unitaire'")

# ğŸ” ContrÃ´le qualitÃ© aprÃ¨s nettoyage
rapport = {
    "doublons_restants": df_clean.duplicated().sum(),
    "valeurs_nulles": df_clean.isna().sum().to_dict(),
    "quantites_negatives": (df_clean['Quantite_vendue'] < 0).sum(),
    "prix_negatifs": (df_clean['Prix_unitaire'] < 0).sum()
}
logging.info(f"Validation aprÃ¨s nettoyage : {rapport}")
print("\nğŸ“‹ Ã‰tat aprÃ¨s nettoyage :")
print(rapport)

# 8ï¸âƒ£ CrÃ©ation dâ€™une colonne calculÃ©e (avec gestion des erreurs)
try:
    df_clean['Total_HT'] = df_clean['Quantite_vendue'] * df_clean['Prix_unitaire']
    logging.info("Colonne 'Total_HT' crÃ©Ã©e avec succÃ¨s")
except Exception as err:
    logging.error(f"Erreur lors du calcul de 'Total_HT' : {err}")

# 9ï¸âƒ£ Normalisation min-max
val_min = df_clean['Total_HT'].min()
val_max = df_clean['Total_HT'].max()
df_clean['Total_HT_normalise'] = (df_clean['Total_HT'] - val_min) / (val_max - val_min)
logging.info("Normalisation Min-Max de la colonne 'Total_HT'")

# ğŸ” AgrÃ©gation par produit
df_resume = df_clean.groupby("Nom_produit")["Total_HT"].sum().reset_index()
df_resume.rename(columns={"Total_HT": "Chiffre_affaires"}, inplace=True)
logging.info("AgrÃ©gation des ventes par produit (Total_HT)")

# ğŸ”„ Documentation finale
doc_resume = {
    "Ã‰tapes rÃ©alisÃ©es": [
        "Suppression des doublons",
        "Nettoyage des valeurs manquantes",
        "Winsorisation sur les colonnes quantitatives",
        "CrÃ©ation de colonnes dÃ©rivÃ©es",
        "AgrÃ©gation des ventes par produit"
    ],
    "ContrÃ´les finaux": {
        "doublons_restants": df_clean.duplicated().sum(),
        "valeurs_manquantes": df_clean.isna().sum().to_dict(),
        "quantites_negatives": (df_clean['Quantite_vendue'] < 0).sum(),
        "prix_negatifs": (df_clean['Prix_unitaire'] < 0).sum()
    }
}
print("\nğŸ“˜ RÃ©sumÃ© des traitements effectuÃ©s :")
print(doc_resume)
logging.info(f"RÃ©sumÃ© final des traitements : {doc_resume}")

# ğŸ’¾ Sauvegarde du jeu de donnÃ©es nettoyÃ©
os.makedirs("archives", exist_ok=True)
horodatage = datetime.now().strftime("%Y%m%d_%H%M%S")
fichier_sortie = f"archives/donnees_filtrees_{horodatage}.csv"
df_clean.to_csv(fichier_sortie, index=False)
print(f"\nâœ… DonnÃ©es sauvegardÃ©es dans : {fichier_sortie}")
logging.info(f"Fichier sauvegardÃ© : {fichier_sortie}")
